<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>SSTV Encoder (Scottie S1)</title>
    <link rel="stylesheet" type="text/css" href="styles.css">
</head>
<body>
    <div class="container">
        <h1>SSTV Encoder (Scottie S1)</h1>
        
        <div class="upload-section">
            <label for="image">Select an image:</label>
            <input type="file" id="image" accept="image/*">
            <p>Image will be resized to 320x256.</p>

            <label for="audioFile">Select an audio:</label>
            <input type="file" id="audioFile" accept="audio/*">
        </div>

        <div class="buttons">
            <button id="play">Play</button>
            <button id="stop" disabled>Stop</button>
            <button id="render">Render</button>
            <button id="decode">Decode SSTV</button>
            <button id="saveFile">Save Audio File</button>
        </div>

        <canvas id="preview" width="320" height="256"></canvas>
        <canvas id="decoded" width="320" height="256"></canvas>

        <audio id="audioPlayer" controls></audio>

        <footer>
            <p><a href="https://a1ex-13.github.io/me/1">üßî About Me</a></p>
        </footer>
    </div>
    
    <div class="progress-container">
        <label for="progress">Processing Progress:</label>
        <progress id="progress" value="0" max="100"></progress>
    </div>

    <script src="index.js"></script>
    <script type="module" src="Render.js"></script>
    <script src="index_decode.js"></script>

    <script>
        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        document.getElementById('image').addEventListener('change', handleImageUpload);

        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        function handleImageUpload(event) {
            const file = event.target.files[0];
            if (!file) return;

            const img = new Image();
            const reader = new FileReader();

            reader.onload = function(e) {
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);

            img.onload = function() {
                const canvas = document.getElementById('preview');
                const ctx = canvas.getContext('2d');
                canvas.width = img.width;
                canvas.height = img.height;
                ctx.drawImage(img, 0, 0);

                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                processImageData(imageData);
            };
        }

        // –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–≤—É–∫–æ–≤–æ–π –≤–æ–ª–Ω—ã
        function processImageData(imageData) {
            // –°–æ–∑–¥–∞–µ–º AudioContext
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();

            // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∑–≤—É–∫–æ–≤—É—é –≤–æ–ª–Ω—É
            const audioData = imageToSound(imageData, audioContext);

            // –°–æ–∑–¥–∞–µ–º AudioBufferSourceNode –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∑–≤—É–∫–∞
            const source = audioContext.createBufferSource();
            audioContext.decodeAudioData(audioData, (buffer) => {
                source.buffer = buffer;
                source.connect(audioContext.destination);
                source.start();
            });

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–≤—É–∫–∞)
            document.getElementById('saveFile').onclick = function() {
                saveAudioToFile(audioContext, audioData);
            };
        }

        // –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∞—É–¥–∏–æ—Ñ–∞–π–ª (–ø—Ä–∏–º–µ—Ä)
        function imageToSound(imageData, audioContext) {
            const samples = new Float32Array(imageData.width * imageData.height * 2); // –î–≤–∞ –∫–∞–Ω–∞–ª–∞ –¥–ª—è —Å—Ç–µ—Ä–µ–æ

            let index = 0;
            for (let y = 0; y < imageData.height; y++) {
                for (let x = 0; x < imageData.width; x++) {
                    const i = (y * imageData.width + x) * 4;
                    const r = imageData.data[i] / 255; // –ö—Ä–∞—Å–Ω—ã–π –∫–∞–Ω–∞–ª
                    const g = imageData.data[i + 1] / 255; // –ó–µ–ª–µ–Ω—ã–π –∫–∞–Ω–∞–ª
                    const b = imageData.data[i + 2] / 255; // –°–∏–Ω–∏–π –∫–∞–Ω–∞–ª

                    // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–≤–µ—Ç –≤ –∑–≤—É–∫ (–ø—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä)
                    samples[index++] = r * 2 - 1; // –õ–µ–≤—ã–π –∫–∞–Ω–∞–ª
                    samples[index++] = g * 2 - 1; // –ü—Ä–∞–≤—ã–π –∫–∞–Ω–∞–ª
                }
            }

            // –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä —Å –¥–∞–Ω–Ω—ã–º–∏
            const buffer = audioContext.createBuffer(2, samples.length / 2, audioContext.sampleRate);
            buffer.getChannelData(0).set(samples.filter((_, i) => i % 2 === 0)); // –õ–µ–≤—ã–π –∫–∞–Ω–∞–ª
            buffer.getChannelData(1).set(samples.filter((_, i) => i % 2 === 1)); // –ü—Ä–∞–≤—ã–π –∫–∞–Ω–∞–ª

            return buffer;
        }

        // –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        function saveAudioToFile(audioContext, audioData) {
            const audioBuffer = audioContext.createBufferSource();
            audioContext.decodeAudioData(audioData, (buffer) => {
                audioBuffer.buffer = buffer;
                const audioBlob = bufferToBlob(buffer);
                const url = URL.createObjectURL(audioBlob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'sstv_audio.wav';
                link.click();
            });
        }

        // –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä–∞ –≤ Blob
        function bufferToBlob(buffer) {
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);
            const audioData = buffer.getChannelData(0);
            const dataSize = audioData.length * 2;
            const bufferLength = dataSize + 44;

            view.setUint8(0, 82); // 'R'
            view.setUint8(1, 73); // 'I'
            view.setUint8(2, 70); // 'F'
            view.setUint8(3, 70); // 'F'
            view.setUint32(4, bufferLength, true);
            view.setUint8(8, 87); // 'W'
            view.setUint8(9, 65); // 'A'
            view.setUint8(10, 86); // 'V'
            view.setUint8(11, 69); // 'E'
            view.setUint8(12, 102); // 'f'
            view.setUint8(13, 109); // 'm'
            view.setUint8(14, 116); // 't'
            view.setUint8(15, 32); // space
            view.setUint32(16, 16, true); // Subchunk1Size
            view.setUint16(20, 1, true); // AudioFormat
            view.setUint16(22, 2, true); // NumChannels
            view.setUint32(24, 44100, true); // SampleRate
            view.setUint32(28, 176400, true); // ByteRate
            view.setUint16(32, 4, true); // BlockAlign
            view.setUint16(34, 16, true); // BitsPerSample
            view.setUint8(36, 100); // 'd'
            view.setUint8(37, 97); // 'a'
            view.setUint8(38, 116); // 't'
            view.setUint8(39, 97); // 'a'
            view.setUint32(40, dataSize, true); // Subchunk2Size

            const wavData = new ArrayBuffer(bufferLength);
            const viewData = new DataView(wavData);
            for (let i = 0; i < audioData.length; i++) {
                viewData.setInt16(i * 2, audioData[i] * 32767, true);
            }

            return new Blob([wavHeader, wavData], { type: 'audio/wav' });
        }
    </script>
</body>
</html>


