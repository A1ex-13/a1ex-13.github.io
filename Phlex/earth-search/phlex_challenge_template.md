# phlex challenge template  

### [ðŸŒ AIforEarthChallenge2024](https://platform.ai4eo.eu/)  
### ðŸ’§ Task 5 - Inputs: geojson + 2 dates; Output: F1  
###  Monitoring and Control:  
>Phlex can be connected to a monitoring system that tracks water quality in real-time,
>such as in a coastal zone.
>This will enable quick responses to deteriorations in water quality.
### Directory Structure:  
```python
project_directory/
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ metadata.yaml                # Metadata file with information about various types of data
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ 5_scaler.joblib              # Scaler for data normalization
â”‚   â””â”€â”€ task_5_model.h5              # Saved model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __pycache__/                 # Cached Python files
â”‚   â”‚     â”œâ”€â”€ datamodule.cpython-311.pyc
â”‚   â”‚     â”œâ”€â”€ factory.cpython-311.pyc
â”‚   â”‚     â”œâ”€â”€ model.cpython-311.pyc
â”‚   â”‚     â”œâ”€â”€ model_clay.cpython-311.pyc
â”‚   â”‚     â”œâ”€â”€ model_clay_v1.cpython-311.pyc
â”‚   â”‚     â””â”€â”€ utils.cpython-311.pyc
â”‚   â”œâ”€â”€ tests/                       # Tests for code verification
â”‚   â”‚     â”œâ”€â”€ test_callbacks.py
â”‚   â”‚     â”œâ”€â”€ test_datamodule.py
â”‚   â”‚     â”œâ”€â”€ test_model.py
â”‚   â”‚     â””â”€â”€ test_trainer.py
â”‚   â”œâ”€â”€ README.md                    # Project documentation and description
â”‚   â”œâ”€â”€ callbacks_wandb.py           # Script for Weights & Biases integration
â”‚   â”œâ”€â”€ datamodule.py                # Module for data loading and preparation
â”‚   â”œâ”€â”€ factory.py                  # Factory method for creating model objects
â”‚   â”œâ”€â”€ model.py                    # Main model
â”‚   â”œâ”€â”€ model_clay.py               # Clay model (specific to your project)
â”‚   â”œâ”€â”€ model_clay_v1.py            # Version 1 of the Clay model
â”‚   â”œâ”€â”€ model_vit.py                # Vision Transformer model (if used)
â”‚   â””â”€â”€ utils.py                    # Utilities and helper functions
â”‚
â”œâ”€â”€ train_data
â”‚   â””â”€â”€ challenge_1.parquet          # Training data
â”‚
â”œâ”€â”€ .DS_Store                        # ?? File created by macOS to store metadata 
â”œâ”€â”€ .gitignore                       # File specifying which files and folders to ignore in Git
â”œâ”€â”€ phlex_v1_challenge_template.ipynb   # Competition notebook template
â”œâ”€â”€ challenge_demo.ipynb             # Demonstration notebook
â””â”€â”€ environment.yml                  # File with project dependencies
```
Here's an example of how to configure `phlex_challenge_template` to work with the folder structure and project.  
This notebook template will include the main steps: data loading, preprocessing, using the model for predictions, and evaluating results.

### Explanation
```
1.Data Loading: Connect and load data from train_data/challenge_1.parquet.
2.Data Preprocessing: The preprocess_data function (check and adjust it in src/datamodule.py) prepares the data for the model.
3.Model Loading: Load the model and scaler from the models/ folder.
4.Prediction: Apply the model for predictions and process the results depending on the task type (classification or regression).
5.Model Evaluation: Use performance evaluation metrics such as accuracy or RMSE.
6.Saving Results: Save the results to a submission.csv file for submission.
```
Be sure to adapt the data paths and functions to match your `project_directory`.

### Phlex Challenge Template
This notebook is designed to help you prepare your submissions for the Phlex Challenge. 

### Setup
Let's start by loading the necessary libraries and setting up our environment.

```python
# Import necessary libraries
import numpy as np
import pandas as pd
import geopandas as gpd
import joblib
import tensorflow as tf
from sklearn.metrics import mean_squared_error, f1_score, accuracy_score
from keras.models import load_model
import os

# Set device
device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'
```

### Load Data  
We'll begin by loading the training data and any additional data needed for evaluation.

```python
# Load training data
train_data_path = 'train_data/challenge_1.parquet'
train_data = pd.read_parquet(train_data_path)

# Display basic information
print(train_data.head())
```
### Preprocess Data
Ensure your data is properly preprocessed according to the challenge requirements. You may need to adjust this based on your specific data.

```python
from src.datamodule import preprocess_data  # Import your preprocessing function

# Preprocess data
X_train, y_train = preprocess_data(train_data)

# Display preprocessed data info
print(X_train.shape, y_train.shape)
```
### Load Model
Load the pre-trained model and scaler from the `models/` directory.

```python
# Load scaler
scaler_path = 'models/5_scaler.joblib'
scaler = joblib.load(scaler_path)

# Load model
model_path = 'models/task_5_model.h5'
model = load_model(model_path)
```
### Predict
Make predictions using the loaded model and preprocessed data.

```python
# Apply scaler to the data
X_train_scaled = scaler.transform(X_train)

# Make predictions
predictions = model.predict(X_train_scaled)

# If it's a classification task
predicted_classes = np.argmax(predictions, axis=1)

# If it's a regression task
# predicted_values = predictions
```
### Evaluate
Evaluate the model performance based on the predictions.

```python
from sklearn.metrics import accuracy_score, mean_squared_error

# If it's a classification task
accuracy = accuracy_score(y_train, predicted_classes)
print(f'Accuracy: {accuracy:.4f}')

# If it's a regression task
mse = mean_squared_error(y_train, predictions)
rmse = np.sqrt(mse)
print(f'RMSE: {rmse:.4f}')
```
### Save Predictions
Save the predictions to a file for submission.

```python
# Create a DataFrame with predictions
submission_df = pd.DataFrame({
    'id': train_data['id'],  # Make sure this column exists in your data
    'predictions': predicted_classes  # Adjust based on your task
})

# Save to CSV
submission_df.to_csv('submission.csv', index=False)
print('Submission file created.')
```
### Summary
In this notebook, we:  
* Loaded and preprocessed data.  
* Loaded a pre-trained model and scaler.  
* Made predictions and evaluated the model.  
* Saved the predictions for submission.

Feel free to adjust this template based on your specific needs and the challenge requirements.  

7.09.24 me & code in the process of learning

[ðŸ§” about me](https://a1ex-13.github.io/me/1)  

[ðŸšª home](https://a1ex-13.github.io)  


